# -*- coding: utf-8 -*-
"""Rock Vs Mine Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Oq63KyaMQKjbbadTCn0f_Lx7g8C8Ai5B

Importing the dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""Data collection and Data processing"""

#Loading dataset to panda dataframe
sonar_data = pd.read_csv('/content/sonar data.csv',header=None)

sonar_data.head()

# Number of rows and columns
sonar_data.shape

sonar_data.describe() # like summary in R language ( statistical measures lil data mte3na)

sonar_data[60].value_counts() # for the last columns which R Or M , count numbers of internal data and their type, for these we got M = 111 , R = 97 , if we had 5 F's , it will display also F = 5

sonar_data.groupby(60).mean() # for each line it calculated the mean value for Mine or Rock, and grouped the values by the last index value = 60 , the R or M

# From 59 are features ( el model mteena behs yetrena aalihom ) last column = 60 , is the label where our model will train on , eli after howa besh ykoun target mte3na when do enter our test data
# Seperating data and labels
X = sonar_data.drop(60,axis=1) # storing the last
Y = sonar_data[60]

print(X) # the cleaned data without last column ( label - target after )
print(Y) # the last column stored here

"""Training and Test data"""

# We are going to split data to train and test data , we gonna apply X_train to match(label) Y_train (training data) after that we are going to use X_test,Y_test to test the model ?
# test_size = 0.1 -> allocation 10% to data , the other 90% lil training
# it has something to do with the distribution of samples in training and test data to have equal power in prediction ?!
# random_state = 1 -> setting the seed to make sure that first random split will happen again and again while spliting data and not start from zero , we'll get same split everytime running the code 10% 90%
X_train , X_test , Y_train , Y_test = train_test_split(X , Y, test_size=0.1,stratify=Y,random_state=1)

print(X.shape,X_train.shape,X_test.shape)

print(X_train)
print(Y_train)

"""Model Training ---> Logistic Regression"""

model = LogisticRegression()

#Training the logistic Regression MODEL with training data
model.fit(X_train,Y_train)

"""Model Evaluation

"""

# accuracy on the training data ( is not always good point to evaluate , you need to see specifity & sensetivity )
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print('Accuracy score on training data ',training_data_accuracy)

# accuracy on the test data | the model never seen this data btw
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print('Accuracy score on test data ',test_data_accuracy)

"""Making the predictive system"""

input_data=(0.0335,0.0134,0.0696,0.1180,0.0348,0.1180,0.1948,0.1607,0.3036,0.4372,0.5533,0.5771,0.7022,0.7067,0.7367,0.7391,0.8622,0.9458,0.8782,0.7913,0.5760,0.3061,0.0563,0.0239,0.2554,0.4862,0.5027,0.4402,0.2847,0.1797,0.3560,0.3522,0.3321,0.3112,0.3638,0.0754,0.1834,0.1820,0.1815,0.1593,0.0576,0.0954,0.1086,0.0812,0.0784,0.0487,0.0439,0.0586,0.0370,0.0185,0.0302,0.0244,0.0232,0.0093,0.0159,0.0193,0.0032,0.0377,0.0126,0.0156)

# chanding the input_data to numpy array
input_data_as_numpy_array=np.asarray(input_data)

# reshape the np array as we arre predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]=='R'):
  print('The object is a Rock')
else:
  print('The object is a Mine')


# Ps : some data identified as rocks while they are mines and vice versa .... :) , need more data to make accurate prediction lol